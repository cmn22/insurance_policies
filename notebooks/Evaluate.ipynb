{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce0cee9e",
   "metadata": {},
   "source": [
    "# Evaluate Notebook\n",
    "\n",
    "This notebook loads the saved model and evaluates it on train and test sets, reporting RMSE and R².\n",
    "It also writes `reports/metrics.json` and, when available, `reports/feature_importance.csv`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050871a2",
   "metadata": {},
   "source": [
    "## 1) Load configuration & resolve paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd87462",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import os, json\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "# Locate the repo root by searching upward for params.yaml\n",
    "def find_repo_root(start: Path | None = None) -> Path:\n",
    "    cur = (start or Path.cwd()).resolve()\n",
    "    for _ in range(10):\n",
    "        if (cur / \"params.yaml\").exists():\n",
    "            return cur\n",
    "        if cur.parent == cur:\n",
    "            break\n",
    "        cur = cur.parent\n",
    "    raise FileNotFoundError(\"Could not find 'params.yaml' in parent directories. Start this notebook from your repo.\")\n",
    "\n",
    "ROOT = find_repo_root(Path.cwd())\n",
    "print(f'Resolved ROOT: {ROOT}')\n",
    "PARAMS_PATH = ROOT / \"params.yaml\"\n",
    "\n",
    "with open(PARAMS_PATH, \"r\") as f:\n",
    "    params = yaml.safe_load(f)\n",
    "\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "PROCESSED = DATA_DIR / \"processed\"\n",
    "MODELS = ROOT / \"models\"\n",
    "REPORTS = ROOT / \"reports\"\n",
    "PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "MODELS.mkdir(parents=True, exist_ok=True)\n",
    "REPORTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "display(params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e0b25d",
   "metadata": {},
   "source": [
    "## 2) Load processed data and trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9430cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from joblib import load\n",
    "\n",
    "X_train = pd.read_csv(PROCESSED / \"X_train.csv\")\n",
    "X_test  = pd.read_csv(PROCESSED / \"X_test.csv\")\n",
    "\n",
    "def read_y(path: Path, n_expected: int) -> pd.Series:\n",
    "    y = pd.read_csv(path).iloc[:, 0]\n",
    "    if len(y) == n_expected:\n",
    "        return y\n",
    "    y2 = pd.read_csv(path, header=None).iloc[:, 0]\n",
    "    if len(y2) == n_expected:\n",
    "        return y2\n",
    "    raise ValueError(f\"Inconsistent length when reading {path}: got {len(y)} (header) and {len(y2)} (no header), expected {n_expected}.\")\n",
    "\n",
    "y_train = read_y(PROCESSED / \"y_train.csv\", len(X_train))\n",
    "y_test  = read_y(PROCESSED / \"y_test.csv\", len(X_test))\n",
    "\n",
    "model_path = MODELS / \"model.joblib\"\n",
    "if not model_path.exists():\n",
    "    raise FileNotFoundError(f\"Model not found at {model_path}. Run the Train notebook first.\")\n",
    "model = load(model_path)\n",
    "\n",
    "print(\"Loaded model and data.\")\n",
    "print(\"Shapes:\")\n",
    "print(\" X_train:\", X_train.shape, \" X_test:\", X_test.shape)\n",
    "print(\" y_train:\", y_train.shape, \" y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad8f1af",
   "metadata": {},
   "source": [
    "## 3) Compute metrics (RMSE, R²)\n",
    "We compute Mean Squared Error, take its square root for RMSE, and compute R² for both train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ccbe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "preds_train = model.predict(X_train)\n",
    "preds_test  = model.predict(X_test)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, preds_train)\n",
    "mse_test  = mean_squared_error(y_test, preds_test)\n",
    "rmse_train = sqrt(mse_train)\n",
    "rmse_test  = sqrt(mse_test)\n",
    "\n",
    "r2_train = r2_score(y_train, preds_train)\n",
    "r2_test  = r2_score(y_test, preds_test)\n",
    "\n",
    "metrics = {\n",
    "    \"rmse\": float(rmse_train),\n",
    "    \"rmse_test\": float(rmse_test),\n",
    "    \"r2\": float(r2_train),\n",
    "    \"r2_test\": float(r2_test),\n",
    "    \"mse\": float(mse_train),\n",
    "    \"mse_test\": float(mse_test),\n",
    "}\n",
    "\n",
    "print(\"Metrics:\")\n",
    "print(json.dumps(metrics, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc21962",
   "metadata": {},
   "source": [
    "## 4) Save reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b90198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "REPORTS.mkdir(parents=True, exist_ok=True)\n",
    "metrics_path = REPORTS / \"metrics.json\"\n",
    "metrics_path.write_text(json.dumps(metrics, indent=2))\n",
    "print(f\"Wrote metrics to: {metrics_path}\")\n",
    "\n",
    "# Optional: save feature importances if available\n",
    "fi_path = None\n",
    "if hasattr(model, \"feature_importances_\"):\n",
    "    feature_names = list(X_train.columns)\n",
    "    fi = (\n",
    "        pd.DataFrame({\"feature\": feature_names, \"importance\": model.feature_importances_})\n",
    "        .sort_values(\"importance\", ascending=False)\n",
    "    )\n",
    "    fi_path = REPORTS / \"feature_importance.csv\"\n",
    "    fi.to_csv(fi_path, index=False)\n",
    "    print(f\"Wrote feature importances to: {fi_path}\")\n",
    "else:\n",
    "    print(\"Model has no feature_importances_.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7f6de4",
   "metadata": {},
   "source": [
    "## 5) Visualize feature importances (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecf81ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if hasattr(model, \"feature_importances_\"):\n",
    "    top = (\n",
    "        pd.Series(model.feature_importances_, index=X_train.columns)\n",
    "        .sort_values(ascending=False)\n",
    "        .head(10)\n",
    "    )\n",
    "    display(top.to_frame(\"importance\"))\n",
    "    plt.figure()\n",
    "    top.sort_values().plot(kind=\"barh\")\n",
    "    plt.title(\"Top 10 Feature Importances\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Model has no feature_importances_. Skipping plot.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
